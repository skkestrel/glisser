---


---

<h2 id="manual-for-code">Manual for code</h2>
<h2 id="timeblock-chart">Timeblock chart</h2>
<p>See <code>glisse_manual.pdf</code> for accompanying diagram. This document describes the main steps in each timeblock. Step durations in the diagram are for a sample integration with 200,000 particles, time block size of 100, 4 SWIFT processes, and approximately 200 particles in encounter.</p>
<ul>
<li>[1] Before any processing happens, we need to make sure to save the particle states at the beginning of the timeblock. If a particle is detected to be in an encounter during the timeblock, it will be reverted to its state at the beginning of the timeblock. We copy the particle arrays to a set of backup arrays.</li>
<li>[2] Start the GPU integration. The integration operates on all particles which are alive at the beginning of the timeblock, but not on particles which are in encounters. This is async. See also [5].</li>
<li>[3] Queue a presort to happen immediately after the GPU integration happens. The presort moves all particles which remain alive after this timeblock to the beginning, and moves all particles which are dead or in encounters <strong>at the end of the timeblock</strong> to the end of the green region (see [4]). This is async. See also [16].</li>
<li>[4] The particle arrays at the beginning of the integration are sectioned into three parts, the green, yellow, and red regions. The green region represents all the particles which the GPU handles (i.e. alive and not in encounter at beginning of the timeblock). The yellow region represents all the particles which the CPU handles (i.e. in an encounter at the beginning of the timeblock). The red region represents all particles which are dead at the beginning of the timeblock; neither the CPU nor GPU touch these particles because they are disabled. These regions must be in this exact order at the beginning of the timeblock. The variable <code>hd.particles.n_alive()</code> refers to the green plus the yellow region combined, while <code>hd.particles.n_encounter()</code> refers to the yellow region. In contrast, <code>dd.particles.n_alive</code> on the GPU refers to just the green region.</li>
<li>[5] Actual integration happens in <code>src/wh.cu</code>. The <code>MVSKernel</code> is called once for each particle. There are some some unused functions in the file which use manual allocation of threads (in <code>MVSKernel_</code>), which are not recommended for use.</li>
<li>[6] See also <code>src/swift.cpp</code>. SWIFT inputs are written to file and processes are spawned. All particles in the yellow region are processed. The same planetary history file is used for all processes, while each process gets its own particle and parameter input file. This SWIFT integration spans two timeblocks, the one before and also the current timeblock. This is because particles which are marked as in encounter at the beginning of the current timeblock have been rolled back to their states at the beginning of the previous timeblock, so the integration must carry on for 2 timeblocks.</li>
<li>[7] In <code>swift_glisse_ext</code>, the planetary history file is in the same format as the GLISSER planetary history file, except the file must contain exactly two timestamps: one at the beginning of the planetary lookup interval, and one at the end.</li>
<li>[8] This step only happens depending on the configuration of <code>Track-Interval</code> in the input parameter file. See <code>save_binary_track()</code> in <code>src/data.cpp</code>. The actual tasks to be performed in this step are set by the driver code (<code>targets/main.cpp</code>), where callback functions are added to the <code>work</code> variable in the <code>Executor</code> right before the current <code>loop()</code> step is called.</li>
<li>[9] Planet interpolation (or planet direct integration). See also <code>src/interp.cpp</code> for interpolation, or <code>integrate_planets_timeblock</code> in <code>src/wh.cpp</code> for direct integration. These functions populate the planetary position logs and <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>h</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">h_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.84444em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathit">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span> log (this is a common acceleration factor used by the GPU integrator). There are always two planetary logs maintained at any time, an old log and a new log. The interpolation or integration functions always overwrite the old log, and the new and old log are swapped right after. Before this function is called, the old log contains planetary locations for the previous timeblock, and the new log contains planetary locations for the current timeblock. After this function is called, the old log contains planetary locations for the current timeblock, and the new log contains planetary locations for the next timeblock.</li>
<li>[10] Planet position and <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>h</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">h_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.84444em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathit">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span> logs are uploaded to the GPU. Like the CPU, there are always two logs maintained on the GPU: the active one, and the inactive one. We always upload logs to the inactive log on the GPU, which means that the upload can happen while particle integration is happening without data corruption. The active log is switched at the very beginning of <code>upload_planet_log</code>, where <code>planet_data_id</code> is incremented.</li>
<li>[11] Particle outputs are read from SWIFT. The particle locations are saved, and all particles are marked as not in encounter (even if SWIFT diagnosed them as still being in an encounter). This is because if they were marked as in encounter, the next timeblock’s encounter integrator would erroneously try to integrate these particles from the start of this timeblock, when in actuality they are already moved to the end of the current timeblock. Instead, we simply mark all particles as out of encounter, and let the GPU diagnose particles which are still in an encounter next timeblock. This will cause the particles to be rolled back to their states at the beginning of next timeblock (= end of current timeblock), which flows seamlessly.</li>
<li>[12] Particle accelerations must be computed if they came back from SWIFT. Recall that in the mvs integrator, the particle accelerations are shared between timesteps. The particle accelerations are calculated once at the very start of the integration (see the constuctor of <code>WHIntegrator</code> in <code>src/wh.cpp</code>), and the assumption is that the particle accelerations will be updated by the GPU and shared between timeblocks. However, particles coming back from SWIFT will not have accelerations. Thus we need to explicitly calculate the particle accelerations.</li>
<li>[13] The encounter particles are uploaded to the GPU. We are uploading particles into the yellow region, which are not operated on by the GPU, so this is safe to do even if the GPU is still working.</li>
<li>[14] SWIFT may have marked some particles as dead, which are denoted by the red diamond. They need to be sorted later to the end of the array.</li>
<li>[15] When the GPU finishes, the GPU may have determined that some particles are now in encounter or dead as well. They need to be sorted later as well.</li>
<li>[16] This is the queued GPU task from [3]. Since it was queued, there is no guarantee that the encounter particles have come back yet. This sort simply moves both dead and encounter particles to the end of the green region. Since this sort does not distinguish dead from encounter particles, I indicate this new region as the blue region which includes a mix of dead and encounter particles.</li>
<li>[17] Wait for the GPU to finish. In fact, this typically takes no time because the GPU is long finished before SWIFT finishes.</li>
<li>[18] Now we perform the continuation of the GPU presort to handle the blue region, and the previously-yellow region. This sort separates encounter particles and dead particles, and creates a new yellow and red region. The newly created red region is merged with the previous red region. Note that all sorts happen on the GPU arrays.</li>
<li>[19] We are back to the state in which we have a nicely separated green, yellow, and red region, so we are ready for the next timeblock. The sorted particles are downloaded to the CPU.</li>
<li>[20] If particles were just marked as being in an encounter, we need to revert their states to the beginning of the timeblock (since the GPU integration is deemed inaccurate). We just copy the particle states from the backup in [1].</li>
<li>[21] If this timeblock happens to the the last timeblock in a lookup interval, we need to perform an encounter resolution immediately so that the particles which were just in an encounter are resolved and in sync with the end of the interval. This encounter happens for just one single timeblock (unlike the typical two timeblocks) and follows largely the same steps as the main encounter routine.</li>
</ul>

